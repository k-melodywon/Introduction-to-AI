# AI & Machine Learning Concepts

## 1. 인공지능에서 지능에 해당하는 기능
인공지능에서 "지능"은 다음과 같은 기능을 포함합니다:
- **학습 (Learning)**: 데이터에서 패턴을 찾고 이를 기반으로 예측 또는 결정을 내리는 능력
- **추론 (Reasoning)**: 주어진 정보에서 논리적인 결론을 도출하는 과정
- **문제 해결 (Problem Solving)**: 목표를 달성하기 위한 최적의 방법을 찾는 과정
- **자연어 이해 및 처리 (Natural Language Processing, NLP)**: 인간의 언어를 이해하고 생성하는 능력
- **지각 (Perception)**: 시각, 청각 등의 감각 데이터를 분석하는 능력
- **자율성 (Autonomy)**: 외부의 개입 없이 스스로 의사 결정을 수행하는 능력

## 2. 인공지능의 종류 (지도학습, 반지도학습, 강화학습)
### 2.1 지도학습 (Supervised Learning)
- 입력 데이터와 정답(레이블)이 함께 주어짐
- 모델이 주어진 데이터에서 패턴을 학습하고 새로운 데이터에 대한 예측 수행
- 예시: 회귀(Regression), 분류(Classification)

### 2.2 반지도학습 (Semi-Supervised Learning)
- 일부 데이터에는 정답(레이블)이 있고, 나머지는 레이블이 없는 데이터로 학습 진행
- 지도학습과 비지도학습의 중간 형태
- 예시: 레이블이 부족한 데이터에서 모델을 학습할 때 사용

### 2.3 강화학습 (Reinforcement Learning)
- 에이전트가 환경과 상호작용하며 보상을 최대화하는 방향으로 학습
- 시뮬레이션 및 게임 AI, 로봇 제어 등에 활용됨
- 주요 개념: 상태(State), 행동(Action), 보상(Reward)

## 3. 전통적인 프로그래밍 vs. 인공지능 프로그램
| 구분 | 전통적인 프로그래밍 | 인공지능 프로그램 |
|------|----------------|----------------|
| 개발 방식 | 규칙 기반 (if-else, 명시적인 로직) | 데이터 기반 학습 |
| 입력 | 명시적인 알고리즘과 데이터 | 데이터와 목표 (목표에 맞게 학습) |
| 출력 | 프로그래머가 직접 정의한 결과 | 학습된 모델이 예측한 결과 |

## 4. 딥러닝 vs. 머신러닝
- **머신러닝**: 데이터에서 패턴을 학습하는 기법, 특징을 사람이 직접 설계하는 방식
- **딥러닝**: 인공신경망(ANN)을 활용하여 자동으로 특징을 추출하는 머신러닝의 하위 분야

## 5. Classification vs. Regression
| 구분 | Classification | Regression |
|------|---------------|------------|
| 목표 | 범주형 데이터 예측 | 연속형 데이터 예측 |
| 예제 | 이메일 스팸 여부 분류 | 주택 가격 예측 |

## 6. 차원의 저주 (Curse of Dimensionality)
- 차원이 증가할수록 데이터가 희소해지는 문제
- 학습이 어려워지고 계산 비용 증가

## 7. 차원 축소 (Dimensionality Reduction)의 필요성
- 불필요한 차원을 제거하여 모델의 성능 향상
- 과적합(Overfitting) 방지 및 계산 비용 절감

## 8. Ridge vs. Lasso (정규화)
| 구분 | Ridge Regression | Lasso Regression |
|------|----------------|----------------|
| 규제 방식 | L2 정규화 | L1 정규화 |
| 특징 | 모든 변수에 패널티 적용 | 불필요한 변수를 0으로 만듦 |

## 9. Overfitting vs. Underfitting
| 구분 | Overfitting | Underfitting |
|------|------------|-------------|
| 특징 | 훈련 데이터에 너무 맞춰져 일반화 부족 | 너무 단순한 모델로 학습 부족 |

## 10. Feature Engineering vs. Feature Selection
| 구분 | Feature Engineering | Feature Selection |
|------|-----------------|-----------------|
| 의미 | 새로운 특징을 생성 | 불필요한 특징을 제거 |

## 11. 데이터 전처리 (Preprocessing)
- **목적**: 데이터 품질 향상, 학습 성능 개선
- **방법**:
  - **노이즈 제거**: 이상치 처리, smoothing
  - **이상치 탐지**: Boxplot, Z-score
  - **결측치 처리**: 평균 대체, 삭제 등

## 12. 탐색적 데이터 분석 (EDA, Exploratory Data Analysis)
- 데이터의 특성을 파악하는 과정
- 주요 기법: 분포 확인, 상관관계 분석

## 13. 회귀에서 절편과 기울기의 의미
- **절편 (Intercept)**: x=0일 때 y값
- **기울기 (Slope)**: x가 증가할 때 y의 변화량
- 딥러닝에서는 가중치(Weight)와 편향(Bias) 개념과 유사

## 14. 교차검증과 K-Fold 교차검증
- **교차검증**: 데이터를 여러 번 나누어 검증하는 기법
- **K-Fold 교차검증**: 데이터를 K개의 부분으로 나누어 여러 번 검증 수행

## 15. 하이퍼파라미터 튜닝
- 모델 성능을 최적화하기 위해 조정하는 파라미터
- 예시: 학습률(Learning Rate), 배치 크기(Batch Size)

## 16. 결정트리에서 불순도 (Impurity) – 지니 계수 (Gini Index)
- 지니 계수: 데이터가 얼마나 섞여 있는지를 측정하는 지표
- 값이 작을수록 더 순수한 데이터셋을 의미

## 17. 앙상블 (Ensemble)
- 여러 개의 모델을 결합하여 성능 향상
- 예시: 랜덤 포레스트(Random Forest), 부스팅(Boosting)

## 18. 부트스트래핑 (Bootstrapping)
- 데이터 샘플링 기법으로, 랜덤하게 여러 번 샘플링하여 새로운 데이터셋 생성

## 19. 배깅 (Bagging)
- 여러 개의 모델을 학습한 후 평균을 내어 예측 성능을 향상시키는 기법

## 20. 주성분 분석 (PCA, Principal Component Analysis)
- 고차원 데이터를 저차원으로 변환하는 기법
- 데이터의 분산을 최대한 보존하면서 차원 축소 수행

